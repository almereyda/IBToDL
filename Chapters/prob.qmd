---
title: Probability Theory
description: |
    A wise man proportions his belief to the evidence.
    --- David Hume
---
\epigraph{A wise man proportions his belief to the evidence.}{--- David Hume}



::: {.content-hidden}
$$
{{< include ../Tex/math_macros.tex >}}
$$

:::

::: {.content-hidden when-format="html"}

# Probability Theory {#ch:probability}

:::

In this chapter, propositional calculus and probability theory are derived from a list of desired characteristics for sceptical agents.

## From Language to Probability {#sec-language_probability}

### Formal Languages {#sec-formal_language}

We, as intelligent agents, do not know how Nature is; we only know how we perceive it. Our ideas are mental pictures of how we imagine Nature. Like in the story of the blind men and the elephant (@fig-elephant), how do we know that our model is the same as someone else's? *Communicating*. We need to communicate with each other to check if our mental picture of Nature, our model, is consistent with the experience of others.[^31]

We use language to describe Nature. However, natural languages, like English, German, Portuguese, are ambiguous, and we need contextual clues and other information to more clearly communicate meaning. To avoid this, an intelligent agent uses formal language.

A *formal language* is a mathematical tool created for precise communication about a specific subject. For example, arithmetic is a language for calculations. Chemists have a language that represents the chemical structures of molecules. Programming languages are formal languages that express computations. In a nutshell, a formal language is a set of words (strings) whose letters (symbols) are taken from an alphabet and are well-formed according to a specific set of rules, grammar. Let $\lang= <\Sigma, \Phi>$ be a formal language: 

\begin{align}
    \Sigma =& \{S_1, S_2, \cdots, S_n\} \text{ is an alphabet,}\\
    \Phi =& {\Phi_1 \cup \Phi_2 \cup \cdots \cup \Phi_k} \text{ is the grammar, where:}\\
    \Phi_1 &\text{ is the set of unary operations}, \nonumber\\
    \Phi_2 &\text{ is the set of binary operations}, \nonumber\\
    &\cdots \nonumber \\
    \Phi_k &\text{ is the set of k-ary operations.}\nonumber
\end{align}

A formal language allows a quantitative description of a state of knowledge and defines how this state can be updated on new evidence.[^32]

With this definition, we can also think that a formal language is what @sowinski2016 calls a *realm of discourse*, all the valid formed *strings*[^33] that one can derive; everything one can *say* about Nature.

Interestingly, formal languages allow us to manipulate representations of the environment without dealing with their semantics. They are the basis of *"Turing's strange inversion"*, (see @sec-turing_strange_inversion) by doing allowed operations on strings, computers can compute at a superhuman speed and accuracy without ever comprehending what they are doing.

### From Rationalism to Propositional Calculus {#sec-from_rationalism}

**Rational Agents** can form representations of a complex world, use deduction as the inference process to derive updated representations, and use these new representations to decide what to do. In other words, rational agents are the consequence of the epistemological view of *rationalism*.

When a rational agent establishes a particular statement's truth value, all statements formed in her knowledge base from that statement instantly feel that update. Therefore, a rational agent cannot hold contradictions.

::: {#prp-desiderata_language}
## Desiderata for a rational language ##
We want to build a language for rational agents with the following desired characteristics:
:::
i.  **knowledge is absolute**; a sentence[^34] can be either true or false;

ii. **unambiguous**; a constructed sentence can only have one meaning;

iii. **consistent**; a language without paradoxes, whatever path chosen to derive a sentence truth value will lead to the same assignment;

iv. **minimal**; uses the most reduced set of symbols possible.

We call $\lang_R= <\Sigma_R, \Phi_R>$ the formal language built from these constraints, where sentences are either axiom symbols or compounded sentences formed using special symbols called operators, each operator denoting one operation, $\phi \in \Phi_R$.

It is possible to prove that $\lang_R$ only needs one operator [@sowinski2016; @jaynes2003]: [NAND]{.sans-serif} (or [XOR]{.sans-serif}), and it is also equivalent to Propositional Calculus.[^35] In other words, Logic is the language that emerges from our desiderata, from rationalism. **Logic is the language of mathematics**.

A point worth mentioning is that using Logic as an agent formal language means the **implicit acceptance** of the constraints above.

### From Empiricism to Probability Theory {#sec-from_empiricism}

The constraints that lead to Logic are very restrictive to use in the real-world; rational language has a comparatively small *realm of discourse*. Hume would say that it is only helpful for *relations of ideas*, talking in the abstract, and not for *matters of facts*, talking about reality.

A realm of discourse to talk about reality needs at least the empiricist perspective where knowledge is justified belief, and that one should *weigh her beliefs to the evidence.* The quantity that specifies to what degree we believe a proposition is true is constrained by other beliefs, i.e., previous experience and evidence gathered.

::: {.definition #def-sceptical_agents}

**Sceptical Agents**, the ones derived from the empiricist epistemology (authors have called these agents epistemic agents [@caticha2008], idealised epistemic agents [@sowinski2016] or robots [@jaynes2003]), beliefs are not independent of each other [@caticha2008], they form an interconnected web that is the agent's knowledge base. The update mechanism, its inference method, follows the principle of minimality, i.e. it tries to minimise the change in the knowledge base.

:::

::: {#prp-desiderata_language_sceptical}
## Desiderata for a sceptical language, Cox's Axioms##

As we did for rational agents, let us state a set of desired characteristics for the language of science, $\lang_S= <\Sigma_S, \Phi_S>$ [@sowinski2016; @caticha2008; @jaynes2003]:
:::

i.  **Knowledge is a set of beliefs, quantifiable by real numbers and dependent on prior evidence:** 
Let $S_i \in \Sigma_S$ be sentences about the world.  Given any two statements $S_1$, $S_2$, the agent must be able to say that $S_1$ is more plausible than $S_2$, or that $S_2$ is more plausible than $S_1$ or that $S_1$ and $S_2$ are equally plausible. Thus we can list statements in an increasing plausibility order. Real numbers can represent this transitive ordering.[^37]
    Let $b$ be a measure of degrees of belief in $S$ given some previous knowledge $K$: [^38]
 
    \begin{align}
            &b: \Sigma_S \to \Real\\
            &b: S \mapsto b(S|K)
    \end{align}
 

     Here we capture that plausibility (degrees of belief) is not a function of a sentence, but a relation between a sentence and a given assumed prior knowledge $K$.


ii. **"Common sense:"**

    The plausibility of compound sentences should be related by some logical function to the plausibility of the sentences that form them. We already showed that a minimal rational language has only one operator. Here, instead of using the [NAND]{.sans-serif} operator, for a matter of familiarity, let us use the almost minimal language with the operators [NOT]{.sans-serif} ($\neg$) and [AND]{.sans-serif} ($\land$). In this setting, we are saying there are such functions $f$ and $g$ that [@sowinski2016]: 

    \begin{align}
            &b(\neg S|K) = f[b(S|K)] \tag{NOT}\\
            &b(S-1 \land S_2 | K) = g[b(S_1|K), b(S_1|S_2), b(S_2|K), b(S_2|S_1)] \tag{AND}
    \end{align}

iii. **Consistency:** The functions $f$ and $g$ must be consistent with the grammar $\Phi$ (production rules). Consistency guarantees that whatever path used to compute the plausibility of a statement in the context of the same knowledge web (the same set of constraints) must lead to the same degree of belief.

     (a) Beliefs that depend on multiple propositions cannot depend on the order in which they are presented.[]{#axiom:order label="axiom:order"}

     (b) No proposition can be arbitrarily ignored.

     (c) Propositions that are identical must be assigned the same degree of belief.

Such desiderata have a name; it is known as **Cox's axioms**, and one can derive the Sum Rule ([@eq-sum_rule]) and the Product Rule ([@eq-product_rule]) from them, therefore, also the Bayes' Theorem ([@thm-bayes]), and reverse-engineer Kolmogorov's Axioms of Probability Theory (that will be seen in @prp-kolmogorov_axioms) [@sowinski2016; @jaynes2003; @caticha2008; @terenin2015].

::: {.column-margin}

![Andrey Kolmogorov, Soviet mathematician.](/Images/kolmogorov){#fig-kolmogorov width=90%}

:::

In other words, Probability Theory is the language that emerges from our desiderata, from empiricism. *‘Probability theory is the Logic of Science’* [@jaynes2003], and our measure $b$ is usually called probability $P$.

Again, here we explicit that by using Bayesian inference to build and communicate concepts of the world (models), we are assuming Cox's axioms above.

### Assumptions and their consequences

Let us take this opportunity to explore what some assumptions mean to human intelligence in particular. It is indisputable[^39] that humans are not rational, neither sceptical agents. The whole idea of imagining an epistemic agent is a consequence of addressing intelligence without human complexities.

However, are humans irrational because of biology or psychology? Are we irrational for lack of will, or could it be that Nature wires the human brain in a way that pr*events* us from following these axioms? Here we argue that biology has an important role. Researchers have found, for instance, that visual acuity can be permanently impaired if there is a sensory deficit during early post-natal development [@wiesel1982]. Futhermore, if the human brain is not exposed to some samples in its infancy, it will never achieve the accuracy level if it had experienced them, regardless of experiencing those examples later. In other words, *human beliefs depend on the order in which pieces of evidence are presented*, contradicting Cox's axiom *iii (a)*.

## Formalizing Probability Theory

We derived **Cox's axioms** from a list of desired properties of the language for sceptical agents. We also know that it is possible to derive Kolmogorov's Axioms (which will be defined soon in @prp-kolmogorov_axioms), from which we will formalise Probability theory.

Several concepts in the following sections are *relations of ideas*, not *matters of fact*. For example, the probability of an *event* E, P(E), can be computed by marginalisation (as we will show in [#sec-marginalisation]), but as discussed before, there are no beliefs in a vacuum. In reality, there is only the probability of an *event* E given some background knowledge $K$. This change of epistemological perspective is essential to be remembered now that we will expose the idealised development of Probability Theory.

## Experiments, Sample Spaces and Events

The set of possible outcomes of an **experiment** is the **sample space** $\Omega$. Let us use the canonical experiment of rolling a dice. In this experiment, the sample space is: 

<!-- ::: {.content-hidden when-format="pdf"} -->

\begin{align}
    \Omega = \left\{\Large{⚀, ⚁, ⚂ , ⚃, ⚄, ⚅ }\large \right\}
\end{align}
An **outcome** or **realisation** is a point $\omega \in \Omega$:
\begin{align}
    \omega_3&= \Large{⚂} \\
    \Omega &= \left\{\large\omega_1= \Large{⚀}\large ,\cdots, \omega_6 = \Large{⚅} \right\}.
\end{align}

<!-- ::: 

::: {.content-hidden when-format="html"}

\begin{align}
    \Omega = \left\{\epsdice{1},\epsdice{2},\epsdice{3},\epsdice{4},\epsdice{5},\epsdice{6} \right\}
\end{align}
 An **outcome** or **realisation** is a point $\omega \in \Omega$: 
 \begin{align}
    \omega_3&=\epsdice{3}\\
    \Omega &= \left\{\omega_1=\epsdice{1},\cdots,\omega_6=\epsdice{6} \right\}.
\end{align}

::: -->


An **Event** is something that can be said about the *experiment*, "The dice rolled to an odd number". It is a true proposition. Nevertheless, easier than writing so much, we denote *events* with letters. **Events are subsets of $\Omega$** (see @fig-event_A). 

<!-- ::: {.content-hidden when-format="pdf"} -->

\begin{align}
    A &= \left\{\large\va_1= \Large{⚀}\large, \va_2= \Large{⚂}\large , \va_3= \Large{⚄}\large \right\}\\
    A &\subset \Omega
\end{align}

<!-- :::

::: {.content-hidden when-format="html"}

\begin{align}
    A &= \left\{\va_1=\epsdice{1}, \va_2=\epsdice{3}, \va_3=\epsdice{5} \right\}\\
    A &\subset \Omega
\end{align}


::: -->

We say that $A_1, A_2, \cdots$ are **mutually exclusive** or **disjoint** *events* if $A_i \cap A_j=\emptyset, \forall i\neq j$. For example, $A$ is the *event* "the dice rolled to the value 5" and $B$ is the *event* "the dice rolled to an even number". In this case, $A$ and $B$ are disjoint (see @fig-disjoint_events).


::: {.colum-body-outer layout-nrow=1}
    ![An *event* $A$.](/Images/eventA){#fig-event_A}
    ![Disjoint events $A$ and $B$: $A \cap B = \emptyset$.](/Images/disjointAB){#fig-disjoint_events}
    ![A partition of $\Omega$.](/Images/partition){#fig-partition}
:::


::: {.column-margin}
Events, disjoint events and partitions.
:::


A **partition** of $\Omega$ is a sequence of disjoint events (sets) $A_i$ (see @fig-partition), where: 
\begin{align}
    A_1, A_2, \cdots A_i \text{ s.t. } (A_1 \cup A_2 \cup A_3 \cdots = \bigcup\limits_{i=1}^{\infty} A_i) = \Omega
\end{align}

## Kolmogorov's definition of Probability {#sec-probability}

::: {.definition #def-probability_distribution}
A function $P: \powerset(\Omega) \to \sR$ that maps any *event* $A$ to a real number $P(A)$ is called the **probability measure** or a **probability distribution** if it satisfies the axioms bellow [@wasserman2013]:
::: 

::: {#prp-kolmogorov_axioms}
## Kolmogorov Axioms ##
:::

**Axiom 1.**  $P(A)\geq 0, \forall A$

**Axiom 2.**  $P(\Omega)=1$

**Axiom 3.**  If $A$ and $B$ are disjoint, i.e. $A \ind B$,[]{#axiom-disjoint} 
$$\begin{aligned}
    P(A \lor B)= P(A)+P(B)
\end{aligned}$${#eq-sum_rule}


Visually, we can represent the probability of an *event* $A$, $P(A)$, as the proportion of the sample space the *event* occupies. To differentiate *events* from their probabilities, we will shade the area of the *event*.

::: {.colum-body-outer layout-nrow=2}

<!-- ![$P(A)\geq 0$.](/Images/pA){#fig-axiom1}

![$P(\Omega)=1$.](/Images/p1){#fig-axiom2}

![$A \cap B = \emptyset \implies P(A)+P(B)$.](/Images/disjointAB){#fig-axiom3}

![$P(\emptyset)=0$.](/Images/emptyspace){#fig-consequence1}

![$B\subset A \to P(B) \leq P(A)$.](/Images/BinA){#fig-consequence2}

![$P(\bar{A})=1-P(A)$.](/Images/complementA){#fig-consequence3} -->

:::

::: {.column-margin}
Kolmogorov's Axioms and their direct consequences.
:::


Directly from the Kolmogorov Axioms, one can derive [@jaynes2003] other properties (see @fig-axiom1 to @fig-axiom3): 

\begin{align}
&P(\emptyset)=0\\
&B \subset A \implies P(B) \leq P(A)\\
&0 \leq P(A) \leq 1\\
&P(\bar{A})=1-P(A).
\end{align}


## Joint event
::: {.column-margin}
![A joint *event* (A, B)](/Images/joint_event){#fig-joint_event}
:::
::: {.definition #def-joint_event}
A joint *event* (A, B) is the set of outcomes where: $$(A, B) = {\omega \in \Omega: (\omega \in A \cap B) }$$ Therefore, $$P(A, B) =P({\omega \in \Omega: (\omega \in A \cap B) })$$
:::

When talking about *events* as propositions, it is straightforward to use logic notation $P(A \land B)$, but when we start to use *random variables* (@sec-random_variables), we will adopt the shorthand notation $P(\rvA, \rvB).$

## Independent events {#sec-independent_events}
 
::: {.definition #def-independence}
Events $A$ and $B$ are **independent** ($A \ind B$) if: 
$$\begin{aligned}
A\neq \emptyset, B\neq \emptyset \implies P(A)>0, P(B)>0\\
P(A, B) = P(A \land B) = P(A) \cdot P(B)
\end{aligned}$${#eq-product_rule}
:::

**Disjoint *events* cannot be independent**, since (from [\[eq:P(A, B)\>0\]][10]) $P(A) \cdot P(B)> 0$, but as disjoint *events* (@fig-disjoint_events) $P(A \land B)=P(\emptyset)=0$, leading to contradiction.

Independence can be assumed or derived by verifying: 
\begin{align}
P(A \land B)= P(A) \cdot P(B).\\
\nonumber \tag{Independent variables}
\end{align}

## Conditional probability

As we have explained before ([1.1.3.0.1]), the plausibility of an outcome or a set of outcomes depends on a web of interconnected prior beliefs. So, what exists are probabilities *conditional* to a given prior assumption.
<!-- ::: {.column-margin}
\begin{gather*}
P(A|B)=\frac{ \includegraphics[width=2cm]{eventAB} }
{ \includegraphics[width=2cm]{eventB}}
\end{gather*}
::: -->

::: {.definition #def-conditional_probability}
If $P(B)>0$ then the **conditional probability** of A given B is: 
:::
$$\begin{aligned}
P(A|B) \eqdef \frac{P(A,B)}{P(B)}
\end{aligned}$${#eq-conditional_probability}

$$\begin{aligned}
P(A, B) = P(A|B)\cdot P(B)
\end{aligned}$${#eq-joint_probability}



Except if $P(A) \equiv P(B)$, $P(A|B) \neq P(B|A)$. 

Also, $P(A|B)=P(A) \iff A \ind B$.[^310]

## Marginal probability {#sec-marginalisation}

::: {.theorem #thm-marginal_probability}

Let $A_1, \cdots, A_k$ be a partition of $\Omega$. Then, for any *event* B, 
$$\begin{aligned}
P(B)=\sum_{i=1}^k P(B|A_i)\cdot P(A_i)
\end{aligned}$${#eq-law_of_total_probabilities}
:::

::: proof

Define $C_i = (B,A_i)$. Let $C_1, \cdots C_k$ be disjoint and $B = \bigcup\limits_{i=1}^k C_i$.\
Therefore:

![An \emph{event} B, a partition \(A_i\) over \(\Omega\), and \(C_i = (B, A_i) \).](/Images/total_probability){#fig-total_probability}
\begin{align}
        P(B) \triangleq &P(\bigcup\limits_{i=1}^k C_i)
        \overset{\text{\ref{eq-sum_rule}}}{=} \sum_i P(C_i) \triangleq \sum_i P(B,A_i) \\
        \overset{\text{\ref{eq-conditional_probability}}}{=} &\sum_{i=1}^k P(B|A_i)\cdot P(A_i) 
\end{align}
◻
:::

## Bayes' theorem {#sec-bayes_theorem}

::: {.theorem #thm-bayes}
Let $A_1, \cdots, A_k$ be a partition of $\Omega$ s.t. $P(A_i)>0, \forall i$ then, $\forall i=1, \cdots, k$: 
\begin{align}
        P(A_i|B)= \frac{P(B|A_i)\cdot P(A_i)}{\sum_i P(B|A_i)\cdot P(A_i)}
\end{align}
:::

::: proof
From equations [@eq-conditional_probability; @eq-joint_probability;@eq-law_of_total_probabilities]: 
\begin{align}
        P(A_i|B)&\overset{\text{\ref{eq-conditional_probability}}}{=}\frac{P(A_i,B)}{P(B)} \overset{\text{\ref{eq-joint_probability}}}{=} \frac{P(B|A_i) \cdot P(A_i)}{P(B)}  \\
        &\overset{\text{\ref{eq-law_of_total_probabilities}}}{=}\frac{P(B|A_i)\cdot P(A_i)}{\sum_{i=1}^k P(B|A_i)\cdot P(A_i)}
\end{align}
◻
:::

We call $P(A_i)$ the **prior** of A, and $P(A_i|B)$ the **posterior** probability of A.

## Random variables {#sec-random_variables}

::: {.definition #def-random_variable}
A **random variable** is a mapping $\rvX:\Omega \to \Real$ that assigns a real number $\rvX(\omega)$ to each outcome $\omega$, $\omega \mapsto \rvX(\omega)$.
:::

Given a random variable $\rvX$, the probability of an outcome $\rx$ can be expressed as: 
\begin{align}
    P(\rvX=\rx) = P(\rvX^{-1}(\rx)) = P(\{\omega \in \Omega: \rvX(\omega)=\rx\})\label{eq:P(X=x)} 
\end{align}

::: {.column-margin}
![A random variable $X$.](/Images/random_variable){#fig-random_variable}
:::

Several works on Probability Theory choose to start by defining random variables, rarely mentioning sample spaces, *events* or the connection with logical propositions.

This usual approach is, nevertheless, confusing. Beyond the fact that random variables are not variables, but functions, nor random, they model uncertain *events*; it is hard to grasp what random variables are without understanding their reasons for being.

The difference between a random variable $\rvX$ and its "realisation" is the difference between a distribution and a sample from that distribution. In particular, a random variable $\rvX$ is "formalised" in terms of a function from the sample space to some result space, typically $\Real$. The realisation of a random variable is "what you get" when an *experiment* is run, and you apply $\rvX$ to *events* that happened.

### Notation abuse

If a *random variable* is a function, how can we write $P(\rvX=4)$ or $P(\rvX > 7)$? Such confusion is due to some notation abuse that became standard in works on probability theory. It is not easy to grasp it initially, but the explanation was already stated at [\[eq:P(X=x)\]][14]. $P(\rvX=\rx)$ is a shorthand for $P(\rvX^{-1}(\rx))$.

Technically, a *random variable* is a function. In practice, it is just a mathematical tool to help us associate propositions with numbers. It is called a *random variable* because the notation abuse treats the function as a variable.

To help clear up such confusion, let us recap a little the notation we have established before:

In the canonical *experiment* of rolling a dice, instead of writing the proposition *"The dice will roll to number 4."* plausibility is $\frac{1}{6}$, it is easier to assign a letter to the proposition, or as we called the event. Let us use *event* $D$ to represent the proposition. Then, we can use $P(D)=\frac{1}{6}$. Now, we are going one step further; instead of using the *event* $D$ we use the *random variable* $\rvD$, in italic, and say $P(\rvD=4)=\frac{1}{6}$.

Notice the difference between a *random variable* and an *event*:[^312] $\rvD$ could assume any value (even $\rvD =7$, which is outside of our *sample space*). Would it not be easier then to use an index to the *event* letters, $D_4$ to value 4, and $D_1$ to value 1, etc.? Not really.

Besides providing this shorter notation, the mapping of the random variable allows us to manipulate *events* as numbers: for example, we can chart probability distributions using random variables, which we cannot cope with *events*.

## Probability Distributions
::: {.column-margin}
![Probability mass function, probability density function, and probability of an interval (hatched area).](/Images/distribution){#fig-distribution}
:::

::: {.definition #def-probability_mass_function}
A probability distribution of a discrete random variable $\rvX$ or **probability mass function (pmf)** is a function $p: \Omega \to [0,1]$ that provides the probabilities of occurrence of different possible outcomes in an *experiment* (sample space):

:::

\begin{align}
        p(\rx) = P(\rvX = \rx), 
\end{align}

::: {.definition #def-probability_density_function}
If $\rvX$ is continuous, $P(\rvX=\rx)\to 0$, therefore we need to use intervals in this case.

:::
A probability distribution of a countinous random variable $\rvX$ in an interval $A$, or **probability density function (pdf)** is a function $p(\rx)$ that measures the probability of randomly selecting a value within the interval $A=[a, b]$, as the area under its curve for the interval A:

<!-- \begin{flalign}
    P(A) &= P[a \leq \rvX \leq b] = \int_{a}^{b} p(\rx) \, d\rx, \text{ and:}\\
    &
    \begin{cases}
        p(\rx) \geq 0, \forall x \\
        \int\limits_{\Real}^{} p(\rx) \, d\rx = 1
    \end{cases}
\end{flalign} -->


Now that we explained what distributions are,[^313] here we highlight some useful distributions:

### Statistical model {#sec-statistical_model}

A statistical model is a function $p_{\theta}(\rx) \equiv p(\rx | \theta)$ representing the relationship between a parameter[^314] $\theta$ and potential outcomes $\rx$ of a random variable $\rvX$. In practice, we usually define a statistical model of a stochastic process for which we do not know the real distribution. Therefore, the parameter $\theta$ has to be inferred from the observed data.

### Uniform distribution {#sec-uniform_distribution}

::: {.column-margin}
![Uniform distribution.](/Images/uniform){#fig-uniform_distribution}
:::

$\rvX \sim \text{Uniform}(a,b)$, if:

\begin{align}
    p(\rx)=
    \begin{cases}
        \frac{1}{b-a} & x \in [a,b]\\
        0 & \rx \notin [a,b]
    \end{cases}
\end{align}

### Normal distribution
::: {.column-margin}
![Normal distribution.](/Images/gaussian){#fig-normal_distribution}
:::
$\rvX \sim \mathcal{N}(\mu, \sigma^2)$, if: 
\begin{align}
    p(\rx)=\frac{1}{\sigma \sqrt{2\pi}}\exp{\Biggl{\{}{-\frac{1}{2\sigma^2}{(x-\mu)}^2}\Biggr{\}}}, \\~x \in \Real \\
\end{align}
where $\mu \in \Real$ (mean) and $\sigma > 0$ (standard deviation). We say that $\rvX$ has a **standard Normal distribution** if $\mu = 0$, $\sigma =1$.

### Exponential distribution
::: {.column-margin}
![Exponential distribution.](/Images/exponential){#fig-exponential_distribution}
:::
$\rvX \sim \text{Exp}(\lambda)$, if: 
\begin{align}
    p(\rx;\lambda) =
    \begin{cases}
        \lambda e^{-\lambda \rx} & \rx \ge 0, \\
        0 & \rx < 0.
    \end{cases}
\end{align}
where $\lambda > 0$ is the *rate parameter* of the distribution.

## Joint Distributions



::: {.definition #def-joint_mass_distribution}
Given a pair of discrete random variables $\rvX$ and $\rvY$, we define the **joint mass function** by $p(\rx, \ry)=P(\rvX=\rx,\rvY=\ry)$.
:::

::: {.column-margin}
![A chart of a joint distribution.](/Images/joint_distribution){#fig-joint_distribution}
:::

::: {.definition #def-joint_density_distribution}
Given a pair of continuous random variables $\rvX$ and $\rvY$, we define the **joint density function** by $p(\rx, \ry)$, where:

i.  $p(\rx, \ry) \geq 0$

ii. $\iint_{-\infty}^{\infty} p(\rx,\ry) \, d\rx d\ry =1$

iii. $\forall A \subset \Real \times \Real, P((\rvX,\rvY)\in A)=\iint_{A}p(\rx,\ry)\, d\rx d\ry$.
:::

## Expectancy, Variance and Covariance

::: {.definition #def-mean}
The **expected value** or **mean** of $\rvX$ is: 
\begin{align}
        \E (\rvX)=\langle \rvX \rangle = \sum_{x} \rx~p(\rx) = \mu = \mu_X
\end{align}
:::

::: {.theorem #thm-sum_rule}
Let $\rvX_1, \cdots, \rvX_n$ be random variables and $a_1, \cdots, a_n$ be constants, then from the *Sum Rule*: 
\begin{align}
        \E \biggl(\sum_i a_i\rvX_i\biggr)=\sum_i a_i(\E (\rvX_i))
\end{align}
:::

::: {.theorem #thm-product_rule}
Let $\rvX_1, \cdots, \rvX_n$ be independent random variables, then from the *Product Rule*: 
\begin{align}
        \E (\prod_i \rvX_i)=\prod_i \E (\rvX_i)
\end{align}
:::

::: {.definition #def-variance}
Let $\rvX$ be a random variable with mean $\mu$. The **variance** of $\rvX$ is defined by: 
\begin{align}
    \sigma^2 = \sigma_{\rvX}^2 =\E {(\rvX - \mu)}^2
\end{align}
assumming this expectation exists. The standard deviation is $\sigma$.
:::

::: {.definition #def-covariance}
Let ${\rvX}$ and ${\rvY}$ be random variables with means $\mu_{\rvX}$ and $\mu_{\rvY}$, and with standard deviations $\sigma_{\rvX}$ and $\sigma_{\rvY}$. The **covariance** between ${\rvX}$ and ${\rvY}$ is defined as [@wasserman2013 p.74]: 
\begin{align}
\operatorname{Cov}({\rvX},{\rvY}) = \E (({\rvX} - \mu_{\rvX})({\rvY} - \mu_{\rvY}))
\end{align}
and the correlation as: 
\begin{align}
\rho = \rho_{{\rvX},{\rvY}} = \rho({\rvX},{\rvY}) = \frac{\operatorname{Cov}({\rvX},{\rvY})}{\sigma_{\rvX} \sigma_{\rvY}}
\end{align}
:::

::: {.theorem #thm-covariance}
The covariance satisfies: 
\begin{align}
\operatorname{Cov}({\rvX},{\rvY})=\E ({\rvX}{\rvY})- \E({\rvX}) \E({\rvY}).
\end{align}
:::

## Independent Sampling

<!-- :::
![](/Images/sampling){#fig-sampling}

An i.i.d. sample (left) and a biased sample (right). Adapted from @mello2018.
::: -->


A *sample* is a set of examples[^315] drawn from a distribution. One common assumption in Machine Learning Theory is that examples are *identically and independently distributed --- i.i.d.* This means that the probability of obtaining a first training example. $(\rx_1, \ry_1)$ does not affect which $(\rx_2, \ry_2)$ will be drawn in the following observation.

The i.i.d. assumption is useful wherever a census of the population of interest, knowing all possible values, is unfeasible. In this usual case, data analysis is carried out using a sample to represent the population. When the sample is i.i.d., each example in the population has the same chance of being observed (@fig-sampling -- left).

If there is a constraint on which examples of the population are sampled, we say that the sample is *biased* (@fig-sampling -- right).

## Concluding Remarks

This chapter derived *Logic* from the definition of knowledge as absolute truth and *Probability Theory* from knowledge as justified beliefs ([\[sec:from_rationalism, sec:from_empiricism\]][16]). To remind that our definition of knowledge is the basis for the Bayesian perspective of probability and that inference methods are languages, we can say (and prefer) that we derived *Bayesian inference* as the language of science. We proved what we claimed in the previous chapter ([\[ch:artificial_intelligence\]][17]).

We needed to define *formal languages* (@sec-formal_language) and assume desiderata for the languages we wanted to build formally (@prp-desiderata_language, @prp-desiderata_language_sceptical). We called *rational agents* the epistemic agents that use Logic as its inference method, and *sceptical agents* use Bayesian inference.

We found out that the desiderata for the sceptical language are equivalent to Cox's axioms (@prp-desiderata_language_sceptical). From Cox's axioms, it is possible to derive Kolmogorov's axioms of Probability Theory. Which made us conclude that Bayesian inference is the language of science.[^316]

From the derivation, we did a basic Statistics review (influenced by [@wasserman2013]). Many essential topics were left out from this short review chapter, where the focus was to present the concepts that we will use later on in this dissertation.

### Assumptions

1.  A definition of intelligence (@def-intelligence)

2.  An epistemic choice on the definition of Knowledge (@sec-rationalism, @sec-empiricism);

3.  A definition of formal language;

4.  Common assumptions of the epistemic agent language (@prp-desiderata_language_sceptical):

    1.  consistency (*Item III*);

    2.  minimality (*Item IV*).

5.  Assumption of the rational agent language (@prp-desiderata_language):

    i.  knowledge is absolute, a set of true or false sentences (*Item I*)
    ii.  the language must be unambiguous (*Item II*).

6.  Assumption of the sceptical agent language (@prp-desiderata_language_sceptical):

    i.  Knowledge is a set of beliefs, quantifiable by real numbers and dependent on prior evidence (*Item I*);

    ii.  Common sense: The plausibility of compound sentences should be related by some logical function to the plausibility of the sentences that form them (*Item II*).

As we have settled that our focus is Deep Learning, which relates to the sceptical agent, we will abstain from keeping the rational language assumptions in our analysis and assume an epistemic agent is sceptical.


::: {.border-bottom}
>
>
>

:::
</BR>


[^31]: We can take this idea further and think that at any moment, we need to communicate with our past selves to check if new evidence is consistent with our prior model.

[^32]: An inference method defines the rules for updating knowledge.

[^33]: Strings, words, sentences, propositions, formulae are names used interchangeably through the literature.

[^34]: A sentence can be either a single symbol or a string formed with several symbols according to the grammar.

[^35]: Proposition is synonym to sentence and Propositional Calculus is also known as Sentential Calculus.

[^36]:   also present this same idea of deriving probability theory from desiderata.

[^37]: We are implicitly assuming that the language we are building has infinite statements. A further discussion on this continuity assumption can be found in .

[^38]: Using $(S|K)$ in a function is a notation abuse that we accept to explain the idea better.

[^39]: Unless you are an economist.

[^310]: Venn diagrams are not helpful to see that the *events* are independent, as it all depends on the areas of intersection and the sizes of A and B, which are tricky to estimate without computational help.

[^311]: Remember: $(B, A) \equiv (B \cap A)$.

[^312]: An *event* can be seen as a special kind of *random variable*. , a random variable $\rvD$ is the truth function (also known as the indicator function) over an event $D$: 
\begin{align}
        \rvD=\truth_D
    \end{align}
    That is the reason one can say that "*random variables* define *events*."

[^313]: In this dissertation, we will use $P(\rvX)$ to express the probability of a random variable, and $p(\rx)$ to represent a *pmf* or *pdf* of the random variable outcomes.

[^314]: In this dissertation we are interested in vector-valued $\theta$.

[^315]: In this dissertation, an element of a sampling is called an *example*.

[^316]: Our definition of knowledge hinted at a Bayesian perspective of knowledge.
