<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.242">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="A wise man proportions his belief to the evidence. — David Hume">

<title>The emergence of
an Information Bottleneck Theory
of Deep Learning
- 3&nbsp; Probability Theory</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../Back/quarto-questions.html" rel="next">
<link href="../Chapters/ai.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../site_libs/quarto-contrib/quarto-project/tufte/styles.css">
<meta property="og:title" content="The emergence of
an Information Bottleneck Theory
of Deep Learning
- 3&nbsp; Probability Theory">
<meta property="og:description" content="A wise man proportions his belief to the evidence.
--- David Hume">
<meta property="og:site-name" content="The emergence of\
an Information Bottleneck Theory\
of Deep Learning\
">
</head>

<body class="nav-sidebar floating slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-title">Probability Theory</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">The emergence of<br>
an Information Bottleneck Theory<br>
of Deep Learning<br>
</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">Welcome</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Chapters/context.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Background</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Chapters/ai.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Artificial Intelligence</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Chapters/prob.html" class="sidebar-item-text sidebar-link active"><span class="chapter-title">Probability Theory</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">Tufte-Quarto</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Back/quarto-questions.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Questions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Back/todo.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">To-dos</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Contents</h2>
   
  <ul>
  <li><a href="#sec:language_probability" id="toc-sec:language_probability" class="nav-link active" data-scroll-target="#sec\:language_probability">From Language to Probability</a>
  <ul class="collapse">
  <li><a href="#sec:formal_language" id="toc-sec:formal_language" class="nav-link" data-scroll-target="#sec\:formal_language">Formal Languages</a></li>
  <li><a href="#sec:from_rationalism" id="toc-sec:from_rationalism" class="nav-link" data-scroll-target="#sec\:from_rationalism">From Rationalism to Propositional Calculus</a></li>
  <li><a href="#sec-from_empiricism" id="toc-sec-from_empiricism" class="nav-link" data-scroll-target="#sec-from_empiricism">From Empiricism to Probability Theory</a></li>
  <li><a href="#assumptions-and-their-consequences" id="toc-assumptions-and-their-consequences" class="nav-link" data-scroll-target="#assumptions-and-their-consequences">Assumptions and their consequences</a></li>
  </ul></li>
  <li><a href="#formalizing-probability-theory" id="toc-formalizing-probability-theory" class="nav-link" data-scroll-target="#formalizing-probability-theory">Formalizing Probability Theory</a></li>
  <li><a href="#experiments-sample-spaces-and-events" id="toc-experiments-sample-spaces-and-events" class="nav-link" data-scroll-target="#experiments-sample-spaces-and-events">Experiments, Sample Spaces and Events</a></li>
  </ul>
</nav>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
    </div>
<!-- main -->
<main class="content page-columns page-full column-body" id="quarto-document-content">

<header id="title-block-header">
<h1 class="title d-none d-lg-block display-7"><span class="chapter-title">Probability Theory</span></h1>

</header>

<p>In this chapter, propositional calculus and probability theory are derived from a list of desired characteristics for sceptical agents.</p>
<section id="sec:language_probability" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec:language_probability">From Language to Probability</h2>
<section id="sec:formal_language" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec:formal_language">Formal Languages</h3>
<div class="page-columns page-full"><p>We, as intelligent agents, do not know how Nature is; we only know how we perceive it. Our ideas are mental pictures of how we imagine Nature. Like in the story of the blind men and the elephant ([[blind_men]][1]), how do we know that our model is the same as someone else’s? <em>Communicating</em>. We need to communicate with each other to check if our mental picture of Nature, our model, is consistent with the experience of others.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p><div class="no-row-height column-margin column-container"><li id="fn1"><p><sup>1</sup>&nbsp;We can take this idea further and think that at any moment, we need to communicate with our past selves to check if new evidence is consistent with our prior model.</p></li></div></div>
<p>We use language to describe Nature. However, natural languages, like English, German, Portuguese, are ambiguous, and we need contextual clues and other information to more clearly communicate meaning. To avoid this, an intelligent agent uses formal language.</p>
<p>A <em>formal language</em> is a mathematical tool created for precise communication about a specific subject. For example, arithmetic is a language for calculations. Chemists have a language that represents the chemical structures of molecules. Programming languages are formal languages that express computations. In a nutshell, a formal language is a set of words (strings) whose letters (symbols) are taken from an alphabet and are well-formed according to a specific set of rules,&nbsp;grammar. Let <span class="math inline">\(\lang= &lt;\Sigma, \Phi&gt;\)</span> be a formal language:</p>
<p><span class="math display">\[\begin{align}
    \Sigma =&amp; \{S_1, S_2, \cdots, S_n\} \text{ is an alphabet,}\\
    \Phi =&amp; {\Phi_1 \cup \Phi_2 \cup \cdots \cup \Phi_k} \text{ is the grammar, where:}\\
    \Phi_1 &amp;\text{ is the set of unary operations}, \nonumber\\
    \Phi_2 &amp;\text{ is the set of binary operations}, \nonumber\\
    &amp;\cdots \nonumber \\
    \Phi_k &amp;\text{ is the set of k-ary operations.}\nonumber
\end{align}\]</span></p>
<div class="page-columns page-full"><p>A formal language allows a quantitative description of a state of knowledge and defines how this state can be updated on new evidence.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p><div class="no-row-height column-margin column-container"><li id="fn2"><p><sup>2</sup>&nbsp;An inference method defines the rules for updating knowledge.</p></li></div></div>
<div class="page-columns page-full"><p>With this definition, we can also think that a formal language is what&nbsp;<span class="citation" data-cites="sowinski2016">Sowinski (<a href="#ref-sowinski2016" role="doc-biblioref">2016</a>)</span> calls a <em>realm of discourse</em>, all the valid formed <em>strings</em><a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> that one can derive; everything one can <em>say</em> about Nature.</p><div class="no-row-height column-margin column-container"><li id="fn3"><p><sup>3</sup>&nbsp;Strings, words, sentences, propositions, formulae are names used interchangeably through the literature.</p></li></div></div>
<p>Interestingly, formal languages allow us to manipulate representations of the environment without dealing with their semantics. They are the basis of <em>“Turing’s strange inversion”</em>, (see [[turing_strange_inversion]][2]) by doing allowed operations on strings, computers can compute at a superhuman speed and accuracy without ever comprehending what they are doing.</p>
</section>
<section id="sec:from_rationalism" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec:from_rationalism">From Rationalism to Propositional Calculus</h3>
<p><strong>Rational Agents</strong> can form representations of a complex world, use deduction as the inference process to derive updated representations, and use these new representations to decide what to do. In other words, rational agents are the consequence of the epistemological view of <em>rationalism</em>.</p>
<p>When a rational agent establishes a particular statement’s truth value, all statements formed in her knowledge base from that statement instantly feel that update. Therefore, a rational agent cannot hold contradictions.</p>
<p><strong>Desiderata for a rational language <a href="" id="sec-desiderata_language"></a></strong></p>
<p>We want to build a language for rational agents with the following desired characteristics:</p>
<ol type="i">
<li><p><strong>knowledge is absolute</strong><span id="absolute_truth" label="absolute_truth"></span>; a sentence<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> can be either true or false;</p></li>
<li><p><strong>unambiguous</strong><span id="unambiguous" label="unambiguous"></span>, a constructed sentence can only have one meaning;</p></li>
<li><p><strong>consistent</strong>; a language without paradoxes, whatever path chosen to derive a sentence truth value will lead to the same assignment;<span id="rational_consistency" label="rational_consistency"></span></p></li>
<li><p><strong>minimal</strong>; uses the most reduced set of symbols possible.<span id="rational_minimality" label="rational_minimality"></span></p></li>
</ol>
<div class="no-row-height column-margin column-container"><li id="fn4"><p><sup>4</sup>&nbsp;A sentence can be either a single symbol or a string formed with several symbols according to the grammar.</p></li></div><p>We call <span class="math inline">\(\lang_R= &lt;\Sigma_R, \Phi_R&gt;\)</span> the formal language built from these constraints, where sentences are either axiom symbols or compounded sentences formed using special symbols called operators, each operator denoting one operation, <span class="math inline">\(\phi \in \Phi_R\)</span>.</p>
<div class="page-columns page-full"><p>It is possible to prove that <span class="math inline">\(\lang_R\)</span> only needs one operator&nbsp;<span class="citation" data-cites="sowinski2016 jaynes2003">(<a href="#ref-sowinski2016" role="doc-biblioref">Sowinski 2016</a>; <a href="#ref-jaynes2003" role="doc-biblioref">Jaynes 2003</a>)</span>: <span class="sans-serif">NAND</span> (or <span class="sans-serif">XOR</span>), and it is also equivalent to Propositional Calculus.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> In other words, Logic is the language that emerges from our desiderata, from rationalism. <strong>Logic is the language of mathematics</strong>.</p><div class="no-row-height column-margin column-container"><li id="fn5"><p><sup>5</sup>&nbsp;Proposition is synonym to sentence and Propositional Calculus is also known as Sentential Calculus.</p></li></div></div>
<p>A point worth mentioning is that using Logic as an agent formal language means the <strong>implicit acceptance</strong> of the constraints above.</p>
</section>
<section id="sec-from_empiricism" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-from_empiricism">From Empiricism to Probability Theory</h3>
<p>The constraints that lead to Logic are very restrictive to use in the real-world; rational language has a comparatively small <em>realm of discourse</em>. Hume would say that it is only helpful for <em>relations of ideas</em>, talking in the abstract, and not for <em>matters of facts</em>, talking about reality.</p>
<p>A realm of discourse to talk about reality needs at least the empiricist perspective where knowledge is justified belief, and that one should <em>weigh her beliefs to the evidence.</em> The quantity that specifies to what degree we believe a proposition is true is constrained by other beliefs, i.e., previous experience and evidence gathered.</p>
<p><strong>Sceptical Agents {#sec:sceptical_agents}</strong></p>
<p>In the sceptical agent, the one derived from the empiricist epistemology (authors have called these agents epistemic agents&nbsp;<span class="citation" data-cites="caticha2008">(<a href="#ref-caticha2008" role="doc-biblioref">Caticha 2008</a>)</span>, idealised epistemic agents&nbsp;<span class="citation" data-cites="sowinski2016">(<a href="#ref-sowinski2016" role="doc-biblioref">Sowinski 2016</a>)</span> or robots&nbsp;<span class="citation" data-cites="jaynes2003">(<a href="#ref-jaynes2003" role="doc-biblioref">Jaynes 2003</a>)</span>), beliefs are not independent of each other&nbsp;<span class="citation" data-cites="caticha2008">(<a href="#ref-caticha2008" role="doc-biblioref">Caticha 2008</a>)</span>, they form an interconnected web that is the agent’s knowledge base. The update mechanism, its inference method, follows the principle of minimality, i.e.&nbsp;it tries to minimise the change in the knowledge base.</p>
<p><strong>Desiderata for a sceptical language {#sec-desiderata_language_sceptical}</strong></p>
<p>As we did for rational agents, let us state a set of desired characteristics for the language of science, <span class="math inline">\(\lang_S= &lt;\Sigma_S, \Phi_S&gt;\)</span> <span class="citation" data-cites="sowinski2016 caticha2008 jaynes2003">(<a href="#ref-sowinski2016" role="doc-biblioref">Sowinski 2016</a>; <a href="#ref-caticha2008" role="doc-biblioref">Caticha 2008</a>; <a href="#ref-jaynes2003" role="doc-biblioref">Jaynes 2003</a>)</span>:</p>
<ol type="i">
<li><p><span id="beliefs" label="beliefs"></span><strong>Knowledge is a set of beliefs, quantifiable by real numbers and dependent on prior evidence:</strong> Let <span class="math inline">\(S_i \in \Sigma_S\)</span> be sentences about the world. Given any two statements <span class="math inline">\(S_1\)</span>, <span class="math inline">\(S_2\)</span>, the agent must be able to say that <span class="math inline">\(S_1\)</span> is more plausible than <span class="math inline">\(S_2\)</span>, or that <span class="math inline">\(S_2\)</span> is more plausible than <span class="math inline">\(S_1\)</span> or that <span class="math inline">\(S_1\)</span> and <span class="math inline">\(S_2\)</span> are equally plausible. Thus we can list statements in an increasing plausibility order. Real numbers can represent this transitive ordering.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a> Let <span class="math inline">\(b\)</span> be a measure of degrees of belief in <span class="math inline">\(S\)</span> given some previous knowledge <span class="math inline">\(K\)</span>: <a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></p>
<p><span class="math display">\[\begin{align}
        &amp;b: \Sigma_S \to \Real\\
        &amp;b: S \mapsto b(S|K)
\end{align}\]</span></p>
<p>Here we capture that plausibility (degrees of belief) is not a function of a sentence, but a relation between a sentence and a given assumed prior knowledge <span class="math inline">\(K\)</span>.</p></li>
<li><p><strong>“Common sense:”</strong><span id="common_sense" label="common_sense"></span></p>
<p>The plausibility of compound sentences should be related by some logical function to the plausibility of the sentences that form them. We already showed that a minimal rational language has only one operator. Here, instead of using the <span class="sans-serif">NAND</span> operator, for a matter of familiarity, let us use the almost minimal language with the operators <span class="sans-serif">NOT</span> (<span class="math inline">\(\neg\)</span>) and <span class="sans-serif">AND</span> (<span class="math inline">\(\land\)</span>). In this setting, we are saying there are such functions <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> that&nbsp;<span class="citation" data-cites="sowinski2016">(<a href="#ref-sowinski2016" role="doc-biblioref">Sowinski 2016</a>)</span>:</p>
<p><span class="math display">\[\begin{align}
        &amp;b(\neg S|K) = f[b(S|K)] \tag{NOT}\\
        &amp;b(S-1 \land S_2 | K) = g[b(S_1|K), b(S_1|S_2), b(S_2|K), b(S_2|S_1)] \tag{AND}
\end{align}\]</span></p></li>
<li><p><strong>Consistency:</strong> The functions <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> must be consistent with the grammar <span class="math inline">\(\Phi\)</span> (production rules). Consistency guarantees that whatever path used to compute the plausibility of a statement in the context of the same knowledge web (the same set of constraints) must lead to the same degree of belief.<span id="consistency" label="consistency"></span></p>
<ol type="a">
<li><p>Beliefs that depend on multiple propositions cannot depend on the order in which they are presented.<span id="axiom:order" label="axiom:order"></span></p></li>
<li><p>No proposition can be arbitrarily ignored.</p></li>
<li><p>Propositions that are identical must be assigned the same degree of belief.</p></li>
</ol></li>
</ol>
<div class="no-row-height column-margin column-container"><li id="fn6"><p><sup>6</sup>&nbsp;We are implicitly assuming that the language we are building has infinite statements. A further discussion on this continuity assumption can be found in&nbsp;.</p></li><li id="fn7"><p><sup>7</sup>&nbsp;Using <span class="math inline">\((S|K)\)</span> in a function is a notation abuse that we accept to explain the idea better.</p></li></div><p>Such desiderata have a name; it is known as Cox’s axioms<span id="cox" label="cox"></span>, and one can derive the Sum Rule and the Product Rule (see [1.4]) from them, therefore, also the Bayes’ Theorem ([1.9]), and reverse-engineer Kolmogorov’s Axioms of Probability Theory (that will be seen in [[sec:kolmogorov_axioms]][3], [[fig:kolmogorov]][4])<span id="future:cox_to_kolmogorov" label="future:cox_to_kolmogorov"></span>&nbsp;<span class="citation" data-cites="sowinski2016 jaynes2003 caticha2008 terenin2015">(<a href="#ref-sowinski2016" role="doc-biblioref">Sowinski 2016</a>; <a href="#ref-jaynes2003" role="doc-biblioref">Jaynes 2003</a>; <a href="#ref-caticha2008" role="doc-biblioref">Caticha 2008</a>; <a href="#ref-terenin2015" role="doc-biblioref">Terenin and Draper 2015</a>)</span>.</p>
<p>In other words, Probability Theory is the language that emerges from our desiderata, from empiricism. <em>‘Probability theory is the Logic of Science’</em> <span class="citation" data-cites="jaynes2003">(<a href="#ref-jaynes2003" role="doc-biblioref">Jaynes 2003</a>)</span>, and our measure <span class="math inline">\(b\)</span> is usually called probability&nbsp;<span class="math inline">\(P\)</span>.</p>
<p>Again, here we explicit that by using Bayesian inference to build and communicate concepts of the world (models), we are assuming Cox’s axioms above.</p>
</section>
<section id="assumptions-and-their-consequences" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="assumptions-and-their-consequences">Assumptions and their consequences</h3>
<div class="page-columns page-full"><p>Let us take this opportunity to explore what some assumptions mean to human intelligence in particular. It is indisputable<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a> that humans are not rational, neither sceptical agents. The whole idea of imagining an epistemic agent is a consequence of addressing intelligence without human complexities.</p><div class="no-row-height column-margin column-container"><li id="fn8"><p><sup>8</sup>&nbsp;Unless you are an economist.</p></li></div></div>
<p>However, are humans irrational because of biology or psychology? Are we irrational for lack of will, or could it be that Nature wires the human brain in a way that pr<em>events</em> us from following these axioms? Here we argue that biology has an important role. Researchers have found, for instance, that visual acuity can be permanently impaired if there is a sensory deficit during early post-natal development&nbsp;<span class="citation" data-cites="wiesel1982">(<a href="#ref-wiesel1982" role="doc-biblioref">Wiesel 1982</a>)</span>. Futhermore, if the human brain is not exposed to some samples in its infancy, it will never achieve the accuracy level if it had experienced them, regardless of experiencing those examples later. In other words, <em>human beliefs depend on the order in which pieces of evidence are presented</em>, contradicting Cox’s axiom&nbsp;[[axiom:order]][5].</p>
</section>
</section>
<section id="formalizing-probability-theory" class="level2">
<h2 class="anchored" data-anchor-id="formalizing-probability-theory">Formalizing Probability Theory</h2>
<p>We derived Cox’s axioms from a list of desired properties of the language for sceptical agents. We also know that it is possible to derive Kolmogorov’s Axioms (which will be defined soon in [[sec:kolmogorov_axioms]][3]) from those axioms. In the next sections, we will use the Kolmogorov Axioms to formalise Probability theory.</p>
<p>Several concepts in the following sections are <em>relations of ideas</em>, not <em>matters of fact</em>. For example, the probability of an <em>event</em> E, P(E), can be computed by marginalisation (as we will show in [1.8]), but as discussed before, there are no beliefs in a vacuum. In reality, there is only the probability of an <em>event</em> E given some background knowledge <span class="math inline">\(K\)</span>. This change of epistemological perspective is essential to be remembered now that we will expose the idealised development of Probability Theory.</p>
</section>
<section id="experiments-sample-spaces-and-events" class="level2">
<h2 class="anchored" data-anchor-id="experiments-sample-spaces-and-events">Experiments, Sample Spaces and Events</h2>
<p>The set of possible outcomes of an <em>experiment</em> is the <em>sample space</em> <span class="math inline">\(\Omega\)</span>. Let us use the canonical <em>experiment</em> of rolling a dice. In this experiment, the sample space is:</p>
<div>
<p><span class="math display">\[\begin{align}
    \Omega = \left\{\Large{⚀, ⚁, ⚂ , ⚃, ⚄, ⚅ }\large \right\}
\end{align}\]</span></p>
<p>An <strong>outcome</strong> or <strong>realisation</strong> is a point <span class="math inline">\(\omega \in \Omega\)</span>: <span class="math display">\[\begin{align}
    \omega_3&amp;= \Large{⚂} \\
    \Omega &amp;= \left\{\large\omega_1= \Large{⚀}\large ,\cdots, \omega_6 = \Large{⚅} \right\}.
\end{align}\]</span></p>
</div>
<p>An <strong>Event</strong> is something that can be said about the <em>experiment</em>, “The dice rolled to an odd number”. It is a true proposition. Nevertheless, easier than writing so much, we denote <em>events</em> with letters. <strong>Events are subsets of <span class="math inline">\(\Omega\)</span></strong> (see [[fig:event_A]][6]).</p>
<div>
<p><span class="math display">\[\begin{align}
    A &amp;= \left\{\large\va_1= \Large{⚀}\large, \va_2= \Large{⚂}\large , \va_3= \Large{⚄}\large \right\}\\
    A &amp;\subset \Omega
\end{align}\]</span></p>
</div>
<p>We say that <span class="math inline">\(A_1, A_2, \cdots\)</span> are <strong>mutually exclusive</strong> or <strong>disjoint</strong> <em>events</em> if <span class="math inline">\(A_i \cap A_j=\emptyset, \forall i\neq j\)</span>. For example, <span class="math inline">\(A\)</span> is the <em>event</em> “the dice rolled to the value 5” and <span class="math inline">\(B\)</span> is the <em>event</em> “the dice rolled to an even number”. In this case, <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are disjoint (see&nbsp;[[fig:disjoint_events]][7]).</p>
<div class="colum-body-outer quarto-layout-panel">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../Images/eventA.svg" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">An <em>event</em> <span class="math inline">\(A\)</span>.</figcaption><p></p>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../Images/disjointAB.svg" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Disjoint events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>: <span class="math inline">\(A \cap B = \emptyset\)</span></figcaption><p></p>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../Images/partition.svg" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">A partition of <span class="math inline">\(\Omega\)</span>.</figcaption><p></p>
</figure>
</div>
</div>
</div>
</div>
<!-- 

::: sidecaption
![Events, disjoint events and partitions.](/Images/event_A.png){#fig:event_A label="fig:event_A"}
![Disjoint events A and B: $A \cap B \eq \emptyset$](/Images/event_A.png){#fig:event_A label="fig:event_A"}
:::

A **partition** of $\Omega$ is a sequence of disjoint events (sets) $A_i$ (see [\[fig:partition\]][8]), where: 
\begin{align}
    A_1, A_2, \cdots A_i \text{ s.t. } (A_1 \cup A_2 \cup A_3 \cdots = \bigcup\limits_{i=1}^{\infty} A_i) = \Omega
\end{align}

## Kolmogorov's definition of Probability {#sec-robability}

[]{#sec:kolmogorov_axioms label="sec:kolmogorov_axioms"}

::: definition

A function $P: \powerset(\Omega) \to \sR$ that maps any *event* $A$ to a real number $P(A)$ is called the **probability measure** or a **probability distribution** if it satisfies Kolmogorov's axioms [@wasserman2013]:

1.  $P(A)\geq 0, \forall A$

2.  $P(\Omega)=1$

3.  If $A$ and $B$ are disjoint, i.e. $A \ind B$,[]{#axiom:disjoint label="axiom:disjoint"} 
\begin{align}
                <!-- P(A \lor B)= P(A)+P(B)\label{eq:sum_rule}\tag{Sum Rule} 
            
\end{align}

::: 

-->
<p>Visually, we can represent the probability of an <em>event</em> <span class="math inline">\(A\)</span>, <span class="math inline">\(P(A)\)</span>, as the proportion of the sample space the <em>event</em> occupies. To differentiate <em>events</em> from their probabilities, we will shade the area of the <em>event</em>.</p>
<div class="sidecaption">
<p>Kolmogorov’s Axioms and their direct consequences.<span id="fig:kolmogorov_axioms" label="fig:kolmogorov_axioms"></span></p>
</div>
<p>Directly from the Kolmogorov Axioms, one can derive&nbsp;<span class="citation" data-cites="jaynes2003">(<a href="#ref-jaynes2003" role="doc-biblioref">Jaynes 2003</a>)</span> other properties (see [[fig:axiom1, fig:axiom2, fig:axiom3]][9]):</p>
<!-- 

\begin{align}
P(\emptyset)&=0\\
B \subset A &\implies P(B) \leq P(A)\\
0 &\leq P(A) \leq 1\\
P(\bar{A})&=1-P(A).
\end{align}

## Joint event

::: definition
A joint *event* (A, B) is the set of outcomes where: $$(A, B) = {\omega \in \Omega: (\omega \in A \cap B) }$$ Therefore, $$P(A, B) =P({\omega \in \Omega: (\omega \in A \cap B) })$$
:::

When talking about *events* as propositions, it is straightforward to use logic notation $P(A \land B)$, but when we start to use *random variables* ([1.10]), we will adopt the shorthand notation $P(\rvA, \rvB)$.

## Independent events {#sec:independent_events}

::: definition
[]{#def:independence label="def:independence"} Events $A$ and $B$ are **independent** ($A \ind B$) if: 
\begin{align}
A\neq \emptyset, B\neq \emptyset \implies P(A)>0, P(B)>0\label{eq:P(A, B)>0}\\
P(A, B) = P(A \land B) = P(A) \cdot P(B)\label{eq:Product_Rule}\\
\nonumber \tag{Product Rule}
\end{align}
:::

**Disjoint *events* cannot be independent**, since (from [\[eq:P(A, B)\>0\]][10]) $P(A) \cdot P(B)> 0$, but as disjoint *events* ([\[fig:disjoint_events\]][7]) $P(A \land B)=P(\emptyset)=0$, leading to contradiction.

Independence can be assumed or derived by verifying: 
\begin{align}
P(A \land B)= P(A) \cdot P(B).\\
\nonumber \tag{Independent variables}
\end{align}

## Conditional probability

As we have explained before ([1.1.3.0.1]), the plausibility of an outcome or a set of outcomes depends on a web of interconnected prior beliefs. So, what exists are probabilities *conditional* to a given prior assumption.

::: definition
If $P(B)>0$ then the **conditional probability** of A given B is: 
\begin{align}
\label{eq:conditional_probability}
P(A|B) \eqdef \frac{P(A,B)}{P(B)}
\end{align}

\begin{align}
\label{eq:joint_probability}
P(A, B) \eqdef P(A|B)\cdot P(B)
\end{align}
:::

Except if $P(A) \equiv P(B)$, $P(A|B) \neq P(B|A)$. Also, $P(A|B)=P(A) \iff A \ind B$.[^310]

## Marginal probability {#marginalisation}

::: theorem
Let $A_1, \cdots, A_k$ be a partition of $\Omega$. Then, for any *event* B, 
\begin{align}
P(B)=\sum_{i=1}^k P(B|A_i)\cdot P(A_i)\label{eq:law_of_total_probabilities} 
\end{align}
:::

::: proof
*Proof.* [^311] Define $C_i = (B,A_i)$. Let $C_1, \cdots C_k$ be disjoint and $B = \bigcup\limits_{i=1}^k C_i$.\
Therefore:


\begin{align}
        P(B) &\triangleq P(\bigcup\limits_{i=1}^k C_i)
        \overset{\text{\ref{eq:sum_rule}}}{=} \sum_i P(C_i)\\
        &\triangleq \sum_i P(B,A_i)
        \overset{\text{\ref{eq:conditional_probability}}}{=} \sum_{i=1}^k P(B|A_i)\cdot P(A_i) \tag{Law of Total Probability}
    
\end{align}
◻
:::

## Bayes' theorem {#sec:bayes_theorem}

::: theorem
Let $A_1, \cdots, A_k$ be a partition of $\Omega$ s.t. $P(A_i)>0, \forall i$ then, $\forall i=1, \cdots, k$: 
\begin{align}
        P(A_i|B)= \frac{P(B|A_i)\cdot P(A_i)}{\sum_i P(B|A_i)\cdot P(A_i)}
    
\end{align}
:::

::: proof
*Proof.* From equations [\[eq:conditional_probability\]][11], [\[eq:joint_probability\]][12] and [\[eq:law_of_total_probabilities\]][13]: 
\begin{align}
        P(A_i|B)&\overset{\text{\ref{eq:conditional_probability}}}{=}\frac{P(A_i,B)}{P(B)} \overset{\text{\ref{eq:joint_probability}}}{=} \frac{P(B|A_i) \cdot P(A_i)}{P(B)}  \\
        &\overset{\text{\ref{eq:law_of_total_probabilities}}}{=}\frac{P(B|A_i)\cdot P(A_i)}{\sum_{i=1}^k P(B|A_i)\cdot P(A_i)}
    
\end{align}
◻
:::

We call $P(A_i)$ the **prior** of A, and $P(A_i|B)$ the **posterior** probability of A.

## Random variables {#sec:random_variables}

::: definition
A **random variable** is a mapping $\rvX:\Omega \to \Real$ that assigns a real number $\rvX(\omega)$ to each outcome $\omega$, $\omega \mapsto \rvX(\omega)$.
:::

Given a random variable $\rvX$, the probability of an outcome $\rx$ can be expressed as: 
\begin{align}
    P(\rvX=\rx) = P(\rvX^{-1}(\rx)) = P(\{\omega \in \Omega: \rvX(\omega)=\rx\})\label{eq:P(X=x)} 
\end{align}

Several works on Probability Theory choose to start by defining random variables, rarely mentioning sample spaces, *events* or the connection with logical propositions.

This usual approach is, nevertheless, confusing. Beyond the fact that random variables are not variables, but functions, nor random, they model uncertain *events*; it is hard to grasp what random variables are without understanding their reasons for being.

The difference between a random variable $\rvX$ and its "realisation" is the difference between a distribution and a sample from that distribution. In particular, a random variable $\rvX$ is "formalised" in terms of a function from the sample space to some result space, typically $\Real$. The realisation of a random variable is "what you get" when an *experiment* is run, and you apply $\rvX$ to *events* that happened.

### Notation abuse

If a *random variable* is a function, how can we write $P(\rvX=4)$ or $P(\rvX > 7)$? Such confusion is due to some notation abuse that became standard in works on probability theory. It is not easy to grasp it initially, but the explanation was already stated at [\[eq:P(X=x)\]][14]. $P(\rvX=\rx)$ is a shorthand for $P(\rvX^{-1}(\rx))$.

Technically, a *random variable* is a function. In practice, it is just a mathematical tool to help us associate propositions with numbers. It is called a *random variable* because the notation abuse treats the function as a variable.

To help clear up such confusion, let us recap a little the notation we have established before:

In the canonical *experiment* of rolling a dice, instead of writing the proposition *"The dice will roll to number 4."* plausibility is $\frac{1}{6}$, it is easier to assign a letter to the proposition, or as we called the event. Let us use *event* $D$ to represent the proposition. Then, we can use $P(D)=\frac{1}{6}$. Now, we are going one step further; instead of using the *event* $D$ we use the *random variable* $\rvD$, in italic, and say $P(\rvD=4)=\frac{1}{6}$.

Notice the difference between a *random variable* and an *event*:[^312] $\rvD$ could assume any value (even $\rvD=7$, which is outside of our *sample space*). Would it not be easier then to use an index to the *event* letters, $D_4$ to value 4, and $D_1$ to value 1, etc.? Not really.

Besides providing this shorter notation, the mapping of the random variable allows us to manipulate *events* as numbers: for example, we can chart probability distributions using random variables, which we cannot cope with *events*.

## Probability Distributions

::: definition
A probability distribution of a discrete random variable $\rvX$ or **probability mass function (pmf)** is a function $p: \Omega \to [0,1]$ that provides the probabilities of occurrence of different possible outcomes in an *experiment* (sample space):


\begin{align}
        p(\rx) = P(\rvX = \rx), \tag{pmf}
    
\end{align}
:::

If $\rvX$ is continuous, $P(\rvX=\rx)\to 0$, therefore we need to use intervals in this case.

::: definition
A probability distribution of a countinous random variable $\rvX$ in an interval $A$, or **probability density function (pdf)** is a function $p(\rx)$ that measures the probability of randomly selecting a value within the interval $A=[a, b]$, as the area under its curve for the interval A:

::: flalign
P(A) &= P\[a b\] = \_a\^b p()   d,\
&

::: cases
p() , x\
\_\^ p()   d= 1
:::
:::
:::

Now that we explained what distributions are,[^313] here we highlight some useful distributions:

### Statistical model {#sec:statistical_model}

A statistical model is a function $p_{\theta}(\rx) \equiv p(\rx | \theta)$ representing the relationship between a parameter[^314] $\theta$ and potential outcomes $\rx$ of a random variable $\rvX$. In practice, we usually define a statistical model of a stochastic process for which we do not know the real distribution. Therefore, the parameter $\theta$ has to be inferred from the observed data.

### Uniform distribution {#sec:uniform_distribution}

$\nonumber \\\rvX \sim \text{Uniform}(a,b)$, if:\

\begin{align}
    p(\rx)=
    \begin{cases}
        \frac{1}{b-a} & x \in [a,b]\\
        0 & \rx \notin [a,b]
    \end{cases}
\end{align}

### Normal distribution

$\nonumber \\\rvX \sim \mathcal{N}(\mu, \sigma^2)$, if: 
\begin{align}
    p(\rx)=\frac{1}{\sigma \sqrt{2\pi}}\exp{\Biggl{\{}{-\frac{1}{2\sigma^2}{(x-\mu)}^2}\Biggr{\}}}, \\~x \in \Real \\
\end{align}
where $\mu \in \Real$ (mean) and $\sigma > 0$ (standard deviation). We say that $\rvX$ has a **standard Normal distribution** if $\mu = 0$, $\sigma =1$.

### Exponential distribution

$\rvX \sim \text{Exp}(\lambda)$, if: 
\begin{align}
    p(\rx;\lambda) =
    \begin{cases}
        \lambda e^{-\lambda \rx} & \rx \ge 0, \\
        0 & \rx < 0.
    \end{cases}
\end{align}
where $\lambda > 0$ is the *rate parameter* of the distribution.

## Joint Distributions

::: definition
Given a pair of discrete random variables $\rvX$ and $\rvY$, we define the **joint mass function** by $p(\rx, \ry)=P(\rvX=\rx,\rvY=\ry)$.
:::

::: definition
Given a pair of continuous random variables $\rvX$ and $\rvY$, we define the **joint density function** by $p(\rx, \ry)$, where:

i.  $p(\rx, \ry) \geq 0$

ii. $\iint_{-\infty}^{\infty} p(\rx,\ry) \, d\rx d\ry =1$

iii. $\forall A \subset \Real \times \Real, P((\rvX,\rvY)\in A)=\iint_{A}p(\rx,\ry)\, d\rx d\ry$.
:::

## Expectancy, Variance and Covariance

::: definition
The **expected value** or **mean** of $\rvX$ is: 
\begin{align}
        \E (\rvX)=\langle \rvX \rangle = \SumInt_x \rx~p(\rx)~dx = \mu = \mu_X
    
\end{align}
:::

::: theorem
Let $\rvX_1, \cdots, \rvX_n$ be random variables and $a_1, \cdots, a_n$ be constants, then from the *Sum Rule*: 
\begin{align}
        \E \biggl(\sum_i a_i\rvX_i\biggr)=\sum_i a_i(\E (\rvX_i))
    
\end{align}
:::

::: theorem
Let $\rvX_1, \cdots, \rvX_n$ be independent random variables, then from the *Product Rule*: 
\begin{align}
        \E (\prod_i \rvX_i)=\prod_i \E (\rvX_i)
    
\end{align}
:::

::: definition
Let $\rvX$ be a random variable with mean $\mu$. The **variance** of $\rvX$ is defined by: 
\begin{align}
        \sigma^2 = \sigma_{\rvX}^2 =\E {(\rvX - \mu)}^2
    
\end{align}
assumming this expectation exists. The standard deviation is $\sigma$.
:::

::: definition
Let ${\rvX}$ and ${\rvY}$ be random variables with means $\mu_{\rvX}$ and $\mu_{\rvY}$, and with standard deviations $\sigma_{\rvX}$ and $\sigma_{\rvY}$. The **covariance** between ${\rvX}$ and ${\rvY}$ is defined as [@wasserman2013 p.74]: 
\begin{align}
        \operatorname{Cov}({\rvX},{\rvY}) = \E (({\rvX} - \mu_{\rvX})({\rvY} - \mu_{\rvY}))
    
\end{align}
and the correlation as: 
\begin{align}
        \rho = \rho_{{\rvX},{\rvY}} = \rho({\rvX},{\rvY}) = \frac{\operatorname{Cov}({\rvX},{\rvY})}{\sigma_{\rvX} \sigma_{\rvY}}
    
\end{align}
:::

::: theorem
The covariance satisfies: 
\begin{align}
        \operatorname{Cov}({\rvX},{\rvY})=\E ({\rvX}{\rvY})- \E({\rvX}) \E({\rvY}).
    
\end{align}
:::

## Independent Sampling

A *sample* is a set of examples[^315] drawn from a distribution. One common assumption in Machine Learning Theory is that examples are *identically and independently distributed --- i.i.d.* This means that the probability of obtaining a first training example. $(\rx_1, \ry_1)$ does not affect which $(\rx_2, \ry_2)$ will be drawn in the following observation.

The i.i.d. assumption is useful wherever a census of the population of interest, knowing all possible values, is unfeasible. In this usual case, data analysis is carried out using a sample to represent the population. When the sample is i.i.d., each example in the population has the same chance of being observed ([\[fig:sampling\]][15] --- left).

If there is a constraint on which examples of the population are sampled, we say that the sample is *biased* ([\[fig:sampling\]][15] --- right).

## Concluding Remarks

This chapter derived *Logic* from the definition of knowledge as absolute truth and *Probability Theory* from knowledge as justified beliefs ([\[sec:from_rationalism, sec:from_empiricism\]][16]). To remind that our definition of knowledge is the basis for the Bayesian perspective of probability and that inference methods are languages, we can say (and prefer) that we derived *Bayesian inference* as the language of science. We proved what we claimed in the previous chapter ([\[ch:artificial_intelligence\]][17]).

We needed to define *formal languages* ([1.1.1]) and assume desiderata for the languages we wanted to build formally ([\[sec:desiderata_language,sec:desiderata_language_sceptical\]][18]). We called *rational agents* the epistemic agents that use Logic as its inference method, and *sceptical agents* use Bayesian inference.

We found out that the desiderata for the sceptical language are equivalent to Cox's axioms ([\[cox\]][19]). From Cox's axioms, it is possible to derive Kolmogorov's axioms of Probability Theory. Which made us conclude that Bayesian inference is the language of science.[^316]

From the derivation, we did a basic Statistics review (influenced by [@wasserman2013]). Many essential topics were left out from this short review chapter, where the focus was to present the concepts that we will use later on in this dissertation.

### Assumptions

1.  A definition of intelligence ([\[def:intelligence\]][20]);

2.  A epistemic choice on the definition of Knowledge ([\[sec:rationalism, sec:empiricism\]][21]);

3.  A definition of formal language;

4.  Common assumptions of the epistemic agent language:

    1.  consistency ([1.1.3.0.2], [\[consistency\]][22] and [1.1.2.0.2], [\[rational_consistency\]][23]);

    2.  minimality ([1.1.2.0.2], [\[rational_minimality\]][24]).

5.  Assumption of the rational agent language:

    1.  knowledge is absolute, a set of true or false sentences ([1.1.2.0.2], [\[absolute_truth\]][25]);

    2.  the language must be unambiguous ([1.1.2.0.2], [\[unambiguous\]][26]).

6.  Assumption of the sceptical agent language:

    1.  Knowledge is a set of beliefs, quantifiable by real numbers and dependent on prior evidence ([1.1.3.0.2], [\[beliefs\]][27]);

    2.  Common sense: The plausibility of compound sentences should be related by some logical function to the plausibility of the sentences that form them ([1.1.3.0.2], [\[common_sense\]][28]).

As we have settled that our focus is Deep Learning, which relates to the sceptical agent, we will abstain from keeping the rational language assumptions in our analysis and assume an epistemic agent is sceptical.


-->
<p>&lt;— [1]: #blind_men {reference-type=“ref” reference=“blind_men”} [2]: #turing_strange_inversion {reference-type=“ref” reference=“turing_strange_inversion”} [1.4]: #sec:probability {reference-type=“ref” reference=“sec:probability”} [1.9]: #sec:bayes_theorem {reference-type=“ref” reference=“sec:bayes_theorem”} [3]: #sec:kolmogorov_axioms {reference-type=“ref” reference=“sec:kolmogorov_axioms”} [4]: #fig:kolmogorov {reference-type=“ref” reference=“fig:kolmogorov”} [5]: #axiom:order {reference-type=“ref” reference=“axiom:order”} [1.8]: #marginalisation {reference-type=“ref” reference=“marginalisation”} [6]: #fig:event_A {reference-type=“ref” reference=“fig:event_A”} [7]: #fig:disjoint_events {reference-type=“ref” reference=“fig:disjoint_events”} [8]: #fig:partition {reference-type=“ref” reference=“fig:partition”} [9]: #fig:axiom1, fig:axiom2, fig:axiom3 {reference-type=“ref” reference=“fig:axiom1, fig:axiom2, fig:axiom3”} [1.10]: #sec:random_variables {reference-type=“ref” reference=“sec:random_variables”} [10]: #eq:P(A, B)&gt;0 {reference-type=“eqref” reference=“eq:P(A, B)&gt;0”} [1.1.3.0.1]: #sec:sceptical_agents {reference-type=“ref” reference=“sec:sceptical_agents”} [11]: #eq:conditional_probability {reference-type=“ref” reference=“eq:conditional_probability”} [12]: #eq:joint_probability {reference-type=“ref” reference=“eq:joint_probability”} [13]: #eq:law_of_total_probabilities {reference-type=“ref” reference=“eq:law_of_total_probabilities”} [14]: #eq:P(X=x) {reference-type=“eqref” reference=“eq:P(X=x)”} [15]: #fig:sampling {reference-type=“ref” reference=“fig:sampling”} [16]: #sec:from_rationalism, sec:from_empiricism {reference-type=“ref” reference=“sec:from_rationalism, sec:from_empiricism”} [17]: #ch:artificial_intelligence {reference-type=“ref” reference=“ch:artificial_intelligence”} [1.1.1]: #sec:formal_language {reference-type=“ref” reference=“sec:formal_language”} [18]: #sec:desiderata_language,sec:desiderata_language_sceptical {reference-type=“ref” reference=“sec:desiderata_language,sec:desiderata_language_sceptical”} [19]: #cox {reference-type=“ref” reference=“cox”} [20]: #def:intelligence {reference-type=“ref” reference=“def:intelligence”} [21]: #sec:rationalism, sec:empiricism {reference-type=“ref” reference=“sec:rationalism, sec:empiricism”} [1.1.3.0.2]: #sec:desiderata_language_sceptical {reference-type=“ref” reference=“sec:desiderata_language_sceptical”} [22]: #consistency {reference-type=“ref” reference=“consistency”} [1.1.2.0.2]: #sec:desiderata_language {reference-type=“ref” reference=“sec:desiderata_language”} [23]: #rational_consistency {reference-type=“ref” reference=“rational_consistency”} [24]: #rational_minimality {reference-type=“ref” reference=“rational_minimality”} [25]: #absolute_truth {reference-type=“ref” reference=“absolute_truth”} [26]: #unambiguous {reference-type=“ref” reference=“unambiguous”} [27]: #beliefs {reference-type=“ref” reference=“beliefs”} [28]: #common_sense {reference-type=“ref” reference=“common_sense”} –&gt; –&gt;</p>


<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-caticha2008" class="csl-entry" role="doc-biblioentry">
Caticha, Ariel. 2008. <span>“Lectures on <span>Probability</span>, <span>Entropy</span>, and <span><span>Statistical</span> Physics</span>.”</span> <a href="https://arxiv.org/abs/0808.0012">https://arxiv.org/abs/0808.0012</a>.
</div>
<div id="ref-jaynes2003" class="csl-entry" role="doc-biblioentry">
Jaynes, E. T. 2003. <em>Probability Theory: The Logic of Science</em>. Cambridge University Press.
</div>
<div id="ref-sowinski2016" class="csl-entry" role="doc-biblioentry">
Sowinski, Damian Radoslaw. 2016. <span>“Complexity and Stability for Epistemic Agents: The Foundations and Phenomenology of Configurational Entropy.”</span> PhD thesis.
</div>
<div id="ref-terenin2015" class="csl-entry" role="doc-biblioentry">
Terenin, Alexander, and David Draper. 2015. <span>“Cox’s Theorem and the Jaynesian Interpretation of Probability.”</span> <a href="https://arxiv.org/abs/1507.06597">https://arxiv.org/abs/1507.06597</a>.
</div>
<div id="ref-wiesel1982" class="csl-entry" role="doc-biblioentry">
Wiesel, Torsten N. 1982. <span>“Postnatal Development of the Visual Cortex and the Influence of Environment.”</span> <em>Nature</em> 299 (5884): 583–91. <a href="https://doi.org/10.1038/299583a0">https://doi.org/10.1038/299583a0</a>.
</div>
</div>
</section>


</main> <!-- /main -->
<script>
    window.MathJax = {
        loader: {
            load: ['[tex]/require','[tex]/epsdice']
        },
        tex: {
            packages: {'[+]': ['require', 'epsdice']},
        },
        "HTML-CSS": {
            availableFonts: ["Neo-Euler"],
        },
    };
</script>

<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation column-body">
  <div class="nav-page nav-page-previous">
      <a href="../Chapters/ai.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-title">Artificial Intelligence</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../Back/quarto-questions.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-title">Questions</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>